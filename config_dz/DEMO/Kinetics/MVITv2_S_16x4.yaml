TRAIN:
  ENABLE: False
  DATASET: kinetics
  BATCH_SIZE: 2
  EVAL_PERIOD: 10
  CHECKPOINT_PERIOD: 10
  AUTO_RESUME: True
  # CHECKPOINT_FILE_PATH: /data/home/dz/checkpoint_log/SlowFast/PretrainPyth/MViTv2_S_16x4_k400.pyth
DATA:
  USE_OFFSET_SAMPLING: True
  DECODING_BACKEND: pyav
  NUM_FRAMES: 16
  SAMPLING_RATE: 4
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 224
  INPUT_CHANNEL_NUM: [3]
  PATH_TO_DATA_DIR: /data/home/dz/Kinetics400/datapath
  PATH_PREFIX: /data/home/dz/Kinetics400
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  PATH_LABEL_SEPARATOR: ','
MVIT:
  ZERO_DECAY_POS_CLS: False
  USE_ABS_POS: False
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  DEPTH: 16
  NUM_HEADS: 1
  EMBED_DIM: 96
  PATCH_KERNEL: (3, 7, 7)
  PATCH_STRIDE: (2, 4, 4)
  PATCH_PADDING: (1, 3, 3)
  MLP_RATIO: 4.0
  QKV_BIAS: True
  DROPPATH_RATE: 0.2
  NORM: "layernorm"
  MODE: "conv"
  CLS_EMBED_ON: True
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 2, 2], [15, 1, 1, 1]]
  DROPOUT_RATE: 0.0
  DIM_MUL_IN_ATT: True
  RESIDUAL_POOLING: True
AUG:
  NUM_SAMPLE: 2
  ENABLE: True
  COLOR_JITTER: 0.4
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  INTERPOLATION: bicubic
  RE_PROB: 0.25
  RE_MODE: pixel
  RE_COUNT: 1
  RE_SPLIT: False
MIXUP:
  ENABLE: True
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  PROB: 1.0
  SWITCH_PROB: 0.5
  LABEL_SMOOTH_VALUE: 0.1
SOLVER:
  ZERO_WD_1D_PARAM: True
  BASE_LR_SCALE_NUM_SHARDS: True
  CLIP_GRAD_L2NORM: 1.0
  BASE_LR: 0.0001
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 1e-6
  WARMUP_START_LR: 1e-6
  WARMUP_EPOCHS: 30.0
  LR_POLICY: cosine
  MAX_EPOCH: 280
  MOMENTUM: 0.9
  WEIGHT_DECAY: 0.05
  OPTIMIZING_METHOD: adamw
  COSINE_AFTER_WARMUP: True
MODEL:
  NUM_CLASSES: 400
  ARCH: mvit
  MODEL_NAME: MViT
  LOSS_FUNC: soft_cross_entropy
  DROPOUT_RATE: 0.5
TEST:
  ENABLE: False
  DATASET: kinetics
  BATCH_SIZE: 2
  NUM_SPATIAL_CROPS: 1
  NUM_ENSEMBLE_VIEWS: 5
  CHECKPOINT_FILE_PATH: /data/home/dz/checkpoint_log/SlowFast/PretrainPyth/MViTv2_S_16x4_k400.pyth
DATA_LOADER:
  NUM_WORKERS: 10
  PIN_MEMORY: False
NUM_GPUS: 1
NUM_SHARDS: 1
RNG_SEED: 0
OUTPUT_DIR: /data/home/dz/checkpoint_log/SlowFast/Output/Demo_Pretrain_MViTv2_S_K400_Date05_28_2139

DEMO:
  ENABLE: True
  # Path to json file providing class_name - id mapping.
  LABEL_FILE_PATH: /data/home/dz/Kinetics400/class_name_id.json
  # Path to input video file.
  INPUT_VIDEO: /data/home/dz/Kinetics400/videos_val/__NrybzYzUg.mp4
  # Path to output video file to write results to.
  # Leave an empty string if you would like to display results to a window.
  OUTPUT_FILE: /data/home/dz/checkpoint_log/SlowFast/Output/Demo_Finetune_MViTv2_S_UCF101_Date05_28_2139
  # Run video reader/writer in the background with multi-threading.
  THREAD_ENABLE: False
  # Number of CPU(s)/processes use to run video visualizer.
  NUM_VIS_INSTANCES: 8
  # Number of clips to skip prediction/visualization
  # (mostly to smoothen/improve display quality with wecam input).
  NUM_CLIPS_SKIP: 0
  # DISPLAY_WIDTH: 224
  # DISPLAY_HEIGHT: 224

# TENSORBOARD:
#   ENABLE: True
#   # PREDICTIONS_PATH: "/data/home/dz/checkpoint_log/SlowFast/PretrainPyth/MViTv2_S_16x4_k400.pyth"
#   LOG_DIR: "/data/home/dz/checkpoint_log/SlowFast/Output/Demo_Pretrain_MViTv2_S_K400_Date05_28_1912/tensorboard"
#   CLASS_NAMES_PATH: "/data/home/dz/Kinetics400/class_name_id.json"
#   MODEL_VIS:
#     ENABLE: True
#     MODEL_WEIGHTS: True # Set to True to visualize model weights.
#     ACTIVATIONS: True # Set to True to visualize feature maps.
#     INPUT_VIDEO: False # Set to True to visualize the input video(s) for the corresponding feature maps.
#     # List of layer names to visualize weights and activations for.
#     LAYER_LIST:  [head/projection] #[blocks/0/attn/qkv, norm, head/projection] # patch_embed,blocks,norm,head
#     GRAD_CAM:
#       ENABLE: False
#       LAYER_LIST: # List of CNN layers to use for Grad-CAM visualization method.
#                   # The number of layer must be equal to the number of pathway(s).