{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/anaconda3/envs/pytorch38/lib/python3.8/site-packages/tqdm-4.65.0-py3.8.egg/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slowfast.utils.parser import load_config, parse_args\n",
    "from slowfast.config.defaults import get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"/home/dz/workspace/SlowFast-main/configs/Test/MVIT_B_16x4_CONV.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(path_to_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'CONTRASTIVE': CfgNode({'T': 0.07, 'DIM': 128, 'LENGTH': 239975, 'QUEUE_LEN': 65536, 'MOMENTUM': 0.5, 'MOMENTUM_ANNEALING': False, 'TYPE': 'mem', 'INTERP_MEMORY': False, 'MEM_TYPE': '1d', 'NUM_CLASSES_DOWNSTREAM': 400, 'NUM_MLP_LAYERS': 1, 'MLP_DIM': 2048, 'BN_MLP': False, 'BN_SYNC_MLP': False, 'LOCAL_SHUFFLE_BN': True, 'MOCO_MULTI_VIEW_QUEUE': False, 'DELTA_CLIPS_MIN': -inf, 'DELTA_CLIPS_MAX': inf, 'PREDICTOR_DEPTHS': [], 'SEQUENTIAL': False, 'SIMCLR_DIST_ON': True, 'SWAV_QEUE_LEN': 0, 'KNN_ON': True}), 'BN': CfgNode({'USE_PRECISE_STATS': False, 'NUM_BATCHES_PRECISE': 200, 'WEIGHT_DECAY': 0.0, 'NORM_TYPE': 'batchnorm', 'NUM_SPLITS': 1, 'NUM_SYNC_DEVICES': 1, 'GLOBAL_SYNC': False}), 'TRAIN': CfgNode({'ENABLE': True, 'KILL_LOSS_EXPLOSION_FACTOR': 0.0, 'DATASET': 'kinetics', 'BATCH_SIZE': 3, 'EVAL_PERIOD': 10, 'CHECKPOINT_PERIOD': 10, 'AUTO_RESUME': True, 'CHECKPOINT_FILE_PATH': '', 'CHECKPOINT_TYPE': 'pytorch', 'CHECKPOINT_INFLATE': False, 'CHECKPOINT_EPOCH_RESET': False, 'CHECKPOINT_CLEAR_NAME_PATTERN': (), 'MIXED_PRECISION': False, 'CHECKPOINT_IN_INIT': False}), 'AUG': CfgNode({'ENABLE': True, 'NUM_SAMPLE': 2, 'COLOR_JITTER': 0.4, 'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1', 'INTERPOLATION': 'bicubic', 'RE_PROB': 0.25, 'RE_MODE': 'pixel', 'RE_COUNT': 1, 'RE_SPLIT': False, 'GEN_MASK_LOADER': False, 'MASK_TUBE': False, 'MASK_FRAMES': False, 'MASK_WINDOW_SIZE': [8, 7, 7], 'MASK_RATIO': 0.0, 'MAX_MASK_PATCHES_PER_BLOCK': None}), 'VIS_MASK': CfgNode({'ENABLE': False}), 'MIXUP': CfgNode({'ENABLE': True, 'ALPHA': 0.8, 'CUTMIX_ALPHA': 1.0, 'PROB': 1.0, 'SWITCH_PROB': 0.5, 'LABEL_SMOOTH_VALUE': 0.1}), 'TEST': CfgNode({'ENABLE': True, 'DATASET': 'kinetics', 'BATCH_SIZE': 2, 'CHECKPOINT_FILE_PATH': '', 'NUM_ENSEMBLE_VIEWS': 10, 'NUM_SPATIAL_CROPS': 1, 'CHECKPOINT_TYPE': 'pytorch', 'SAVE_RESULTS_PATH': '', 'NUM_TEMPORAL_CLIPS': []}), 'RESNET': CfgNode({'TRANS_FUNC': 'bottleneck_transform', 'NUM_GROUPS': 1, 'WIDTH_PER_GROUP': 64, 'INPLACE_RELU': True, 'STRIDE_1X1': False, 'ZERO_INIT_FINAL_BN': False, 'ZERO_INIT_FINAL_CONV': False, 'DEPTH': 50, 'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]], 'SPATIAL_STRIDES': [[1], [2], [2], [2]], 'SPATIAL_DILATIONS': [[1], [1], [1], [1]]}), 'X3D': CfgNode({'WIDTH_FACTOR': 1.0, 'DEPTH_FACTOR': 1.0, 'BOTTLENECK_FACTOR': 1.0, 'DIM_C5': 2048, 'DIM_C1': 12, 'SCALE_RES2': False, 'BN_LIN5': False, 'CHANNELWISE_3x3x3': True}), 'NONLOCAL': CfgNode({'LOCATION': [[[]], [[]], [[]], [[]]], 'GROUP': [[1], [1], [1], [1]], 'INSTANTIATION': 'dot_product', 'POOL': [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]}), 'MODEL': CfgNode({'ARCH': 'mvit', 'MODEL_NAME': 'MViT', 'NUM_CLASSES': 400, 'LOSS_FUNC': 'soft_cross_entropy', 'SINGLE_PATHWAY_ARCH': ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit'], 'MULTI_PATHWAY_ARCH': ['slowfast'], 'DROPOUT_RATE': 0.5, 'DROPCONNECT_RATE': 0.0, 'FC_INIT_STD': 0.01, 'HEAD_ACT': 'softmax', 'ACT_CHECKPOINT': False, 'DETACH_FINAL_FC': False, 'FROZEN_BN': False, 'FP16_ALLREDUCE': False}), 'MVIT': CfgNode({'MODE': 'conv', 'POOL_FIRST': False, 'CLS_EMBED_ON': True, 'PATCH_KERNEL': [3, 7, 7], 'PATCH_STRIDE': [2, 4, 4], 'PATCH_PADDING': [1, 3, 3], 'PATCH_2D': False, 'EMBED_DIM': 96, 'NUM_HEADS': 1, 'MLP_RATIO': 4.0, 'QKV_BIAS': True, 'DROPPATH_RATE': 0.2, 'LAYER_SCALE_INIT_VALUE': 0.0, 'DEPTH': 16, 'NORM': 'layernorm', 'DIM_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]], 'HEAD_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]], 'POOL_KV_STRIDE': [], 'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8], 'POOL_Q_STRIDE': [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]], 'POOL_KVQ_KERNEL': [3, 3, 3], 'ZERO_DECAY_POS_CLS': False, 'NORM_STEM': False, 'SEP_POS_EMBED': True, 'DROPOUT_RATE': 0.0, 'USE_ABS_POS': True, 'REL_POS_SPATIAL': False, 'REL_POS_TEMPORAL': False, 'REL_POS_ZERO_INIT': False, 'RESIDUAL_POOLING': False, 'DIM_MUL_IN_ATT': False, 'SEPARATE_QKV': False, 'HEAD_INIT_SCALE': 1.0, 'USE_MEAN_POOLING': False, 'USE_FIXED_SINCOS_POS': False, 'REV': CfgNode({'ENABLE': False, 'RESPATH_FUSE': 'concat', 'BUFFER_LAYERS': [], 'RES_PATH': 'conv', 'PRE_Q_FUSION': 'avg'})}), 'MASK': CfgNode({'ENABLE': False, 'MAE_ON': False, 'MAE_RND_MASK': False, 'PER_FRAME_MASKING': False, 'TIME_STRIDE_LOSS': True, 'NORM_PRED_PIXEL': True, 'SCALE_INIT_BY_DEPTH': False, 'DECODER_EMBED_DIM': 512, 'DECODER_SEP_POS_EMBED': False, 'DEC_KV_KERNEL': [], 'DEC_KV_STRIDE': [], 'PRETRAIN_DEPTH': [15], 'HEAD_TYPE': 'separate', 'DECODER_DEPTH': 0, 'PRED_HOG': False}), 'SLOWFAST': CfgNode({'BETA_INV': 8, 'ALPHA': 8, 'FUSION_CONV_CHANNEL_RATIO': 2, 'FUSION_KERNEL_SZ': 5}), 'DATA': CfgNode({'PATH_TO_DATA_DIR': '/home/dz/workspace/SlowFast-main/datapath/kinetics', 'PATH_LABEL_SEPARATOR': ',', 'PATH_PREFIX': '', 'NUM_FRAMES': 16, 'SAMPLING_RATE': 4, 'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229], 'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]], 'PATH_TO_PRELOAD_IMDB': '', 'MEAN': [0.45, 0.45, 0.45], 'INPUT_CHANNEL_NUM': [3], 'STD': [0.225, 0.225, 0.225], 'TRAIN_JITTER_SCALES': [256, 320], 'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0], 'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333], 'USE_OFFSET_SAMPLING': True, 'TRAIN_JITTER_MOTION_SHIFT': False, 'TRAIN_CROP_SIZE': 224, 'TEST_CROP_SIZE': 224, 'TARGET_FPS': 30, 'TRAIN_JITTER_FPS': 0.0, 'DECODING_BACKEND': 'pyav', 'DECODING_SHORT_SIZE': 256, 'INV_UNIFORM_SAMPLE': False, 'RANDOM_FLIP': True, 'MULTI_LABEL': False, 'ENSEMBLE_METHOD': 'sum', 'REVERSE_INPUT_CHANNEL': False, 'TRAIN_CROP_NUM_TEMPORAL': 1, 'TRAIN_CROP_NUM_SPATIAL': 1, 'COLOR_RND_GRAYSCALE': 0.0, 'LOADER_CHUNK_SIZE': 0, 'LOADER_CHUNK_OVERALL_SIZE': 0, 'SKIP_ROWS': 0, 'TIME_DIFF_PROB': 0.0, 'SSL_COLOR_JITTER': False, 'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4], 'SSL_COLOR_HUE': 0.1, 'SSL_MOCOV2_AUG': False, 'SSL_BLUR_SIGMA_MIN': [0.0, 0.1], 'SSL_BLUR_SIGMA_MAX': [0.0, 2.0], 'IN22K_TRAINVAL': False, 'IN22k_VAL_IN1K': '', 'IN_VAL_CROP_RATIO': 0.875, 'DUMMY_LOAD': False}), 'SOLVER': CfgNode({'BASE_LR': 0.0001, 'LR_POLICY': 'cosine', 'COSINE_END_LR': 1e-06, 'GAMMA': 0.1, 'STEP_SIZE': 1, 'STEPS': [], 'LRS': [], 'MAX_EPOCH': 200, 'MOMENTUM': 0.9, 'DAMPENING': 0.0, 'NESTEROV': True, 'WEIGHT_DECAY': 0.05, 'WARMUP_FACTOR': 0.1, 'WARMUP_EPOCHS': 30.0, 'WARMUP_START_LR': 1e-06, 'OPTIMIZING_METHOD': 'adamw', 'BASE_LR_SCALE_NUM_SHARDS': True, 'COSINE_AFTER_WARMUP': True, 'ZERO_WD_1D_PARAM': True, 'CLIP_GRAD_VAL': None, 'CLIP_GRAD_L2NORM': 1.0, 'LARS_ON': False, 'LAYER_DECAY': 1.0, 'BETAS': (0.9, 0.999)}), 'TASK': '', 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SHARD_ID': 0, 'OUTPUT_DIR': '/home/dz/workspace/SlowFast-main/output/Test', 'RNG_SEED': 0, 'LOG_PERIOD': 10, 'LOG_MODEL_INFO': True, 'DIST_BACKEND': 'nccl', 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}), 'DATA_LOADER': CfgNode({'NUM_WORKERS': 8, 'PIN_MEMORY': True, 'ENABLE_MULTI_THREAD_DECODE': False}), 'DETECTION': CfgNode({'ENABLE': False, 'ALIGNED': True, 'SPATIAL_SCALE_FACTOR': 16, 'ROI_XFORM_RESOLUTION': 7}), 'AVA': CfgNode({'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/', 'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/', 'TRAIN_LISTS': ['train.csv'], 'TEST_LISTS': ['val.csv'], 'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'], 'TRAIN_PREDICT_BOX_LISTS': [], 'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'], 'DETECTION_SCORE_THRESH': 0.9, 'BGR': False, 'TRAIN_USE_COLOR_AUGMENTATION': False, 'TRAIN_PCA_JITTER_ONLY': True, 'TEST_FORCE_FLIP': False, 'FULL_TEST_ON_VAL': False, 'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt', 'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv', 'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv', 'IMG_PROC_BACKEND': 'cv2'}), 'MULTIGRID': CfgNode({'EPOCH_FACTOR': 1.5, 'SHORT_CYCLE': False, 'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476], 'LONG_CYCLE': False, 'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)], 'BN_BASE_SIZE': 8, 'EVAL_FREQ': 3, 'LONG_CYCLE_SAMPLING_RATE': 0, 'DEFAULT_B': 0, 'DEFAULT_T': 0, 'DEFAULT_S': 0}), 'TENSORBOARD': CfgNode({'ENABLE': False, 'PREDICTIONS_PATH': '', 'LOG_DIR': '', 'CLASS_NAMES_PATH': '', 'CATEGORIES_PATH': '', 'CONFUSION_MATRIX': CfgNode({'ENABLE': False, 'FIGSIZE': [8, 8], 'SUBSET_PATH': ''}), 'HISTOGRAM': CfgNode({'ENABLE': False, 'SUBSET_PATH': '', 'TOPK': 10, 'FIGSIZE': [8, 8]}), 'MODEL_VIS': CfgNode({'ENABLE': False, 'MODEL_WEIGHTS': False, 'ACTIVATIONS': False, 'INPUT_VIDEO': False, 'LAYER_LIST': [], 'TOPK_PREDS': 1, 'COLORMAP': 'Pastel2', 'GRAD_CAM': CfgNode({'ENABLE': True, 'LAYER_LIST': [], 'USE_TRUE_LABEL': False, 'COLORMAP': 'viridis'})}), 'WRONG_PRED_VIS': CfgNode({'ENABLE': False, 'TAG': 'Incorrectly classified videos.', 'SUBSET_PATH': ''})}), 'DEMO': CfgNode({'ENABLE': False, 'LABEL_FILE_PATH': '', 'WEBCAM': -1, 'INPUT_VIDEO': '', 'DISPLAY_WIDTH': 0, 'DISPLAY_HEIGHT': 0, 'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', 'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DETECTRON2_THRESH': 0.9, 'BUFFER_SIZE': 0, 'OUTPUT_FILE': '', 'OUTPUT_FPS': -1, 'INPUT_FORMAT': 'BGR', 'CLIP_VIS_SIZE': 10, 'NUM_VIS_INSTANCES': 2, 'PREDS_BOXES': '', 'THREAD_ENABLE': False, 'NUM_CLIPS_SKIP': 0, 'GT_BOXES': '', 'STARTING_SECOND': 900, 'FPS': 30, 'VIS_MODE': 'thres', 'COMMON_CLASS_THRES': 0.7, 'UNCOMMON_CLASS_THRES': 0.3, 'COMMON_CLASS_NAMES': ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)'], 'SLOWMO': 1})})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dz/anaconda3/envs/pytorch38/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/dz/anaconda3/envs/pytorch38/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from slowfast.datasets import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = loader.construct_loader(cfg, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_iter, (inputs, labels, index, time, meta) in enumerate(\n",
    "        train_loader\n",
    "    ):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 16, 224, 224)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0]),len(inputs[0][0]),len(inputs[0][0][0]),len(inputs[0][0][0][0]),len(inputs[0][0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 16, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 224, 224])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = inputs[0][0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 224, 224, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.permute(1,2,3,0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, d in enumerate(data):\n",
    "    d = d.numpy()\n",
    "    cv2.imwrite('outputimg/{}.png'.format(idx), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4444, 2.4444, 2.4444,  ..., 0.7745, 0.7703, 0.8225],\n",
       "        [2.4444, 2.4444, 2.4444,  ..., 0.8461, 0.7650, 0.8613],\n",
       "        [2.4444, 2.4444, 2.4444,  ..., 0.9249, 0.8243, 0.8471],\n",
       "        ...,\n",
       "        [1.7452, 1.7894, 1.7929,  ..., 2.0446, 2.0066, 1.9665],\n",
       "        [1.7342, 1.7603, 1.7739,  ..., 2.0187, 2.0208, 2.0043],\n",
       "        [1.7464, 1.7545, 1.7701,  ..., 2.0863, 2.0362, 2.0252]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
